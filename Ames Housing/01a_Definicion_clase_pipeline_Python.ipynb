{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anexo 01a: Definición de la clase **pipeline** en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeLine:\n",
    "    \n",
    "    def __init__(self, dataframe, nominales=None, ordinales=None, numericas=None, target=None):\n",
    "        \"\"\"\n",
    "            Inicializador de clase\n",
    "\n",
    "            :param dataframe: pandas DataFrame\n",
    "            :param nominales=None: lista se strings con nombre de columnas clasificadas como nominales\n",
    "            :param ordinales=None: lista se strings con nombre de columnas clasificadas como ordinales\n",
    "            :param numericas=None: lista se strings con nombre de columnas clasificadas como numéricas\n",
    "            :param target='SalePrice': string con el nombre de la columna de la variable 'objetivo'\n",
    "\n",
    "            El instancia/objeto creado contiene las siguiwentes propiedades de clase:\n",
    "\n",
    "            :nominales: lista de con el nombre de las variables clasificadas como nominales\n",
    "            :ordinales: lista de con el nombre de las variables clasificadas como ordinales\n",
    "            :numericas: lista de con el nombre de las variables clasificadas como numéricas\n",
    "            :target: sting con el nombre de la variables target/objetivo\n",
    "            :columns: lista con el nombre de todas las variables del dataframe\n",
    "            :dataframe: pandas DataFrame que contiene el set de datos \n",
    "        \"\"\"\n",
    "        self.target = target\n",
    "        self.df = dataframe.copy()\n",
    "        self.columns = self.df.columns\n",
    "        self.nominales = list(nominales) \n",
    "        self.ordinales = list(ordinales) \n",
    "        self.numericas = list(numericas) \n",
    "\n",
    "    def addCols(self, colsDict=None):\n",
    "        \"\"\"    \n",
    "            Añade variables nuevas creadas a la propiedades de clase: nominales, ordinales y numéricas.\n",
    "                                Actualiza además la propiedad columns\n",
    "\n",
    "            :param colsDic=None: columnas a añadir. Se necesita crear un diccionario con la siguiente\n",
    "                                forma: {\"nominales\": [vars], \"ordinales\": [vars], \"numericas\": [vars]}\n",
    "        \"\"\"            \n",
    "        if colsDict is not None:\n",
    "            for key, vals in colsDict.items():\n",
    "                if key == 'nominales':\n",
    "                    self.nominales.extend(vals)\n",
    "                elif key == 'ordinales':\n",
    "                    self.ordinales.extend(vals)\n",
    "                elif key == 'numericas':\n",
    "                    self.numericas.extend(vals)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            self.columns = self.df.columns\n",
    "        \n",
    "    def remCols(self, cols=None):\n",
    "        \"\"\"    \n",
    "            Elimina variables de las propiedades de clase: nominales, ordinales y numéricas y \n",
    "                                 actualiza además la propiedad columns\n",
    "\n",
    "            :param cols=None: lista de strings con el nombre de las variables a eliminar.\n",
    "        \"\"\"         \n",
    "        self.df.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "        if cols is not None:\n",
    "            for col in cols:\n",
    "                if col in self.nominales:\n",
    "                    self.nominales.remove(col)\n",
    "                elif col in self.ordinales:\n",
    "                    self.ordinales.remove(col)\n",
    "                elif col in self.numericas:\n",
    "                    self.numericas.remove(col)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            self.columns = self.df.columns  \n",
    "        \n",
    "    def elimReg(self, index=None):\n",
    "        \"\"\"   \n",
    "            Elimina registros/observaciones \n",
    "\n",
    "            :param index=None: lista con los índices de los registros/obsevaciones a eliminar\n",
    "        \"\"\"   \n",
    "        self.df.drop(index, axis=0, inplace=True)\n",
    "    \n",
    "    def chgCatNone(self, cols=None, fill='None'): \n",
    "        \"\"\"    \n",
    "            Recategoriza variables con datos 'missings' \n",
    "\n",
    "            :param cols=None: lista de strings con el nombre de las variables a recategorizar.\n",
    "            :param fill='None': Valor de sustitución en las variables con categorías 'NaN'\n",
    "        \"\"\"   \n",
    "        self.df[cols] = self.df[cols].apply(lambda x: x.fillna(fill), axis=0)\n",
    "            \n",
    "    def indicatorMiss(self, cols=None, concat=False):\n",
    "        \"\"\"    \n",
    "            Genera variables indicadoras dicotómicas de la presencia de observaciones missings manteniendo las\n",
    "                            variables originales.\n",
    "\n",
    "            :param cols=None: lista de strings con el nombre de las variables de las que se quieren generar\n",
    "            varibles indicadoras.\n",
    "            :param concat=False: booleano que indica si se quiere o no concatenar las variables indicadoras\n",
    "            generadas a la propiedad de clase 'dataframe'.\n",
    "\n",
    "            Valor retorno: en el caso de concat=False se devuelve un pandas DataFrame con las variables \n",
    "            indicadoras generadas. \n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        from sklearn.impute import MissingIndicator\n",
    "        \n",
    "        if cols is not None:\n",
    "            names = [col + \"_miss\" for col in cols]\n",
    "            dfmiss = pd.DataFrame(MissingIndicator(features='missing-only', error_on_new=False).fit_transform(self.df[cols]), \n",
    "                                columns = names, dtype=np.int64)\n",
    "            \n",
    "            if concat == False:\n",
    "                return dfmiss\n",
    "                                \n",
    "            elif concat == True:\n",
    "                self.df = pd.concat([self.df, dfmiss], axis=1)\n",
    "                self.addCols({'nominales': names})\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def imputerVar(self, cols=None, metodoCont=\"median\", metodoCat=\"most_frequent\"):\n",
    "        \"\"\"    \n",
    "            Imputa valores a los missings de las variables pasadas por parámetro según los métodos determinados\n",
    "            a través de los parámetros 'metodoCont' y 'metodoCat' para las variables continuas y categóricas\n",
    "            respectivamente.\n",
    "\n",
    "            :param cols=None: lista de strings con el nombre de las variables a imputar.\n",
    "            :param metodoCont='median': método de inmputación para variables continuas. Son válidos los métodos \n",
    "            'mean' para la media, 'median' para la mediana, 'most_frequent' para la moda y 'constant' para una \n",
    "            constante.\n",
    "            :param metodoCat='most_frequent': método de inmputación para variables categóricas. Son válidos los \n",
    "            métodos 'most_frequent' para la moda y 'constant' para una constante.           \n",
    "        \"\"\"\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        \n",
    "        if cols is not None:\n",
    "            nom= []\n",
    "            ordn = []\n",
    "            num = []\n",
    "            \n",
    "            #separa variables por tipo\n",
    "            for var in cols:\n",
    "                if var in self.nominales:\n",
    "                    nom.append(var)\n",
    "                elif var in self.ordinales:\n",
    "                    ordn.append(var)\n",
    "                elif var in self.numericas:\n",
    "                    num.append(var)\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            if len(num) > 0:\n",
    "                self.df[num] = SimpleImputer(strategy=metodoCont).fit_transform(self.df[num])\n",
    "            if len(ordn) > 0:\n",
    "                self.df[ordn] = SimpleImputer(strategy=metodoCat).fit_transform(self.df[ordn])\n",
    "            if len(nom) > 0:\n",
    "                self.df[nom] = SimpleImputer(strategy=metodoCat).fit_transform(self.df[nom])\n",
    "        else:\n",
    "            pass  \n",
    "            \n",
    "    def featureVCramers(self, cols=None, y=None, threshold=0.3):\n",
    "        \"\"\"\n",
    "            Calcula la importancia de las variables, respecto a la variable target/objetivo, según la \n",
    "            VCrammer.\n",
    "\n",
    "            :param cols=None: lista de strings con nombre de las variables a comparar\n",
    "            :param y=None: variable target/objetivo de comparación\n",
    "            :param threshold=0.3\n",
    "\n",
    "            Valor de retorno: devuelve un objeto pandas Serie con el resultado de la VCrammer ordenando\n",
    "            las variables de mayor a menor de acuerdo a la importancia según dicho criterio. \n",
    "        \"\"\"\n",
    "        import scipy.stats as ss\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        \n",
    "        VC = {}\n",
    "    \n",
    "        for col in cols:\n",
    "            confusion_matrizCont = pd.crosstab(self.df[col], self.df[y])\n",
    "            chi2 = ss.chi2_contingency(confusion_matrizCont)[0]\n",
    "            n = confusion_matrizCont.sum().sum()\n",
    "            phi2 = chi2/n\n",
    "            r, k = confusion_matrizCont.shape\n",
    "            phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n",
    "            rcorr = r-((r-1)**2)/(n-1)\n",
    "            kcorr = k-((k-1)**2)/(n-1)\n",
    "        \n",
    "            VC.update({col: np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))})\n",
    "        \n",
    "        ps = pd.DataFrame(pd.Series(VC).sort_values(ascending=False), columns=['VCrammer'])\n",
    "            \n",
    "        return ps[ps.VCrammer > threshold].style.background_gradient()\n",
    "\n",
    "    def featureCorrel(self, cols=None, y=None, threshold=0.6):\n",
    "        \"\"\"\n",
    "            Calcula la importancia de las variables, respecto a la variable target/objetivo, según la \n",
    "            el valor de la correlación.\n",
    "\n",
    "            :param cols=None: lista de strings con nombre de las variables a comparar\n",
    "            :param y=None: variable target/objetivo de comparación.\n",
    "\n",
    "            Valor de retorno: devuelve un objeto pandas Serie con el resultado de la correlación ordenando\n",
    "            las variables de mayor a menor de acuerdo a la importancia según dicho criterio. \n",
    "        \"\"\"\n",
    "        dfCorr = self.df[cols + [y]].corr()[[y]].sort_values(by=str(y), ascending=False)[1:]\n",
    "        dfCorr.columns = ['Pearson Corr']\n",
    "        return dfCorr[abs(dfCorr['Pearson Corr']) > threshold].style.background_gradient()\n",
    "    \n",
    "    def nzv(self, cols=None, threshold=0.995, thresholdRel = 95/5, delete=True):\n",
    "        \"\"\"\n",
    "            Determina variables cuya relación entre frecuencia más elevada y la total es superior al parámetro \n",
    "            threshold. Se retornando dichas variables.\n",
    "\n",
    "            :param cols=None: lista de strings con nombre de las variables a calcular\n",
    "            :param threshold=0.995: umbral por el que que se determinada las variables que tienen menos variación.\n",
    "            calcula la relación entre la moda y el total de observaciones.\n",
    "            :param thresholdRel=95/5: umbral por el que que se determinada las variables que tienen menos variación.\n",
    "            Calcula la relación entre la moda y la segunda categoría más frecuente.\n",
    "            :param delete=True: indicador que determina si las variables capturadas tiene que ser eliminadas o no\n",
    "            dependiendo si el valor es True o False respectivamente. Por defecto son eliminadas.\n",
    "\n",
    "            Valor de retorno: se retorna una lista de strings con los nombres de  las variables con menos variación\n",
    "            si 'delete' es False. Si 'delete' es True se borran las variables estimadas\n",
    "        \"\"\"        \n",
    "        if cols is not None:\n",
    "            nzv = []\n",
    "            \n",
    "            for col in cols:\n",
    "                counts = self.df[col].value_counts()\n",
    "                \n",
    "                cond1 = counts.iloc[0] / len(self.df) > threshold\n",
    "                try:\n",
    "                    cond2 = counts.iloc[0] / counts.iloc[1] > thresholdRel\n",
    "                except IndexError:\n",
    "                    cond2 = True\n",
    "                \n",
    "                if cond1 and cond2:\n",
    "                    nzv.append(col)\n",
    "            \n",
    "            if delete == False:\n",
    "                return nzv\n",
    "            elif delete == True:\n",
    "                self.remCols(nzv)\n",
    "                return nzv\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    def ordEncoder(self, cols=None, categorias=None):\n",
    "        \"\"\"\n",
    "            Codifica las variables ordinales asígnándoles un número de acuerdo a un orden.\n",
    "\n",
    "            :param cols=None: lista de strings con nombre de las variables ordinales a calcular\n",
    "            :param categorias=None: lista de listas. Las listas internas incluyen las categorías de las variables\n",
    "            a codificas. Ver listado 'cat' más abajo.\n",
    "\n",
    "            Lista 'cat':\n",
    "            cat = [[\"Reg\", \"IR1\", \"IR2\", \"IR3\"], #LotShape\n",
    "                [\"AllPub\", \"NoSewr\", \"NoSeWa\", \"ELO\"], #Utilities\n",
    "                [\"Gtl\", \"Mod\", \"Sev\"], #LandSlope\n",
    "                [\"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\"], #ExternQual   \n",
    "                [\"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\"], #ExternCond\n",
    "                [\"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\", \"None\"], #BsmtQual\n",
    "                [\"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\", \"None\"], #BsmtCond\n",
    "                [\"Gd\", \"Av\", \"Mn\", \"No\", \"None\"], #BsmtExposure\n",
    "                [\"GLQ\", \"ALQ\", \"BLQ\", \"Rec\", \"LwQ\", \"Unf\", \"None\"], #BsmtFinType1\n",
    "                [\"GLQ\", \"ALQ\", \"BLQ\", \"Rec\", \"LwQ\", \"Unf\", \"None\"], #BsmtFinType2\n",
    "                [\"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\"], #HeatingQC  \n",
    "                [\"SBrkr\", \"FuseA\", \"FuseF\", \"FuseP\", \"Mix\", \"None\"], #Electrical\n",
    "                [\"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\"], #KitchenQual\n",
    "                [\"Typ\", \"Min1\", \"Min2\", \"Mod\", \"Maj1\", \"Maj2\", \"Sev\", \"Sal\"], #Functional\n",
    "                [\"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\", \"None\"], #FireplaceQu\n",
    "                [\"Fin\", \"RFn\", \"Unf\", \"None\"], #GarageFinish\n",
    "                [\"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\", \"None\"], #GarageQual\n",
    "                [\"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\", \"None\"], #GarageCond\n",
    "                [\"Y\", \"P\", \"N\"], #PavedDrive \n",
    "                [\"Ex\", \"Gd\", \"TA\", \"Fa\", \"None\"], #PoolQC\n",
    "                [\"GdPrv\", \"MnPrv\", \"GdWo\", \"MnWw\", \"None\"], #Fence]\n",
    "                [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], #OverallQual\n",
    "                [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] #OverallCond\n",
    "        \"\"\"   \n",
    "        from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "        if cols is not None:\n",
    "            self.df[cols] = OrdinalEncoder(categories=categorias).fit_transform(self.df[cols])\n",
    "\n",
    "    def ohEncoder(self, cols=None):\n",
    "        \"\"\"\n",
    "            Genera variables 'dummies' (One Hot Encoding OHE) de las variables pasadas como parámetro. \n",
    "\n",
    "            :param cols=None: lista de strings con nombre de las variables categóricas para el OHE.\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "\n",
    "        if cols is not None:\n",
    "\n",
    "            self.df[cols] = self.df[cols].astype(\"object\")\n",
    "\n",
    "            dff = pd.get_dummies(self.df[cols], drop_first= True, prefix=cols)\n",
    "            \n",
    "            self.remCols(cols)\n",
    "\n",
    "            self.df = pd.concat([self.df, dff], axis=1)\n",
    "            self.nominales = []\n",
    "            self.numericas.extend(dff.columns)\n",
    "\n",
    "            self.columns = self.df.columns\n",
    "\n",
    "    def normVar(self, cols=None):\n",
    "        \"\"\"\n",
    "            Aplica transformaciones óptimas de tipo 'Yeo-Johnson' de las variables numéricas pasadas como \n",
    "            parámetro. \n",
    "\n",
    "            :param cols=None: lista de strings con nombre de las variables numéricas para ser transformadas.\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "        if cols is not None:\n",
    "\n",
    "            columns = list(map(lambda x: x + \"_norm\", cols))\n",
    "            dff = pd.DataFrame(PowerTransformer().fit_transform(self.df[cols]), columns = columns)\n",
    "\n",
    "            self.df = pd.concat([self.df, dff], axis=1)\n",
    "\n",
    "            self.numericas.extend(columns)\n",
    "\n",
    "            self.columns = self.df.columns\n",
    "\n",
    "    def scalers(self, cols=None, metodo='StandardScaler'):\n",
    "        \"\"\"\n",
    "            Aplica transformaciones de escalado de las variables numéricas pasadas como parámetro de acuerdo \n",
    "            al parámero 'metodo'. \n",
    "\n",
    "            :param cols=None: lista de strings con nombre de las variables numéricas para ser escaladas.\n",
    "            :param metodo='StandardScaler': indica el método de escalado a aplicar. Los posibles valores son:\n",
    "            StandardScaler, RobustScaler, MinMaxScaler      \n",
    "        \"\"\"\n",
    "        from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "        if cols is not None:\n",
    "            if metodo == 'StandardScaler':\n",
    "                self.df[cols] = StandardScaler().fit_transform(self.df[cols])\n",
    "            if metodo == 'MinMaxScaler':\n",
    "                self.df[cols] = MinMaxScaler().fit_transform(self.df[cols])  \n",
    "            if metodo == 'RobustScaler':\n",
    "                self.df[cols] = RobustScaler().fit_transform(self.df[cols])\n",
    "\n",
    "    def featureEng(self):\n",
    "        \"\"\"\n",
    "            Genera las nuevas variables construidas a partir de las variables del dataset original.\n",
    "            Añade variables nuevas creadas a la propiedades de clase: nominales, ordinales y numéricas.\n",
    "            Actualiza además la propiedad columns. \n",
    "        \"\"\"\n",
    "        ########################## Numéricas ########################## \n",
    "        #self.df['YrBltAndRemod'] = self.df['YearBuilt'] + self.df['YearRemodAdd']   \n",
    "     \n",
    "        self.df['TotalSF'] = self.df['TotalBsmtSF'] + self.df['1stFlrSF'] + self.df['2ndFlrSF'] + self.df['GarageArea']\n",
    "        \n",
    "        self.df['Total_sqr_footage'] = self.df['BsmtFinSF1'] + self.df['BsmtFinSF2'] + self.df['1stFlrSF'] + self.df['2ndFlrSF']\n",
    "\n",
    "        self.df['Total_Bathrooms'] = self.df['FullBath'] + (0.5 * self.df['HalfBath']) + self.df['BsmtFullBath'] + (0.5 * self.df['BsmtHalfBath'])\n",
    "\n",
    "        self.df['Total_porch_sf'] = self.df['OpenPorchSF'] + self.df['3SsnPorch'] + self.df['EnclosedPorch'] + self.df['ScreenPorch'] + self.df['WoodDeckSF']\n",
    "\n",
    "        # self.df['Avg_NeigSalePrice'] = self.df[\"Neighborhood\"].map(dict(self.df.groupby(\"Neighborhood\")[self.target].median()))\n",
    "\n",
    "        ########################## Nominales ########################## \n",
    "        self.df['haspool'] = self.df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        self.df['has2ndfloor'] = self.df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        self.df['hasgarage'] = self.df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        self.df['hasbsmt'] = self.df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        self.df['hasfireplace'] = self.df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        self.df['hasporch'] = self.df['Total_porch_sf'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        self.df[\"hasRemodeled\"] = (self.df[\"YearRemodAdd\"] - self.df[\"YearBuilt\"]).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        self.df[\"MSSubClassMap\"] = self.df[\"MSSubClass\"].map({20: \"1-story\", 30: \"1-story\", 40: \"1-story\", 120: \"1-story\",  \n",
    "                                                           45: \"1-1/2-story\", 50: \"1-1/2-story\", 150: \"1-1/2-story\",\n",
    "                                                           60: \"2-story\", 70: \"2-story\", 75: \"2-story\", 160: \"2-story\", 190: \"2-story\" ,\n",
    "                                                           80: \"1-story\", 85: \"1-story\", \n",
    "                                                           90: \"1/2-story\", \n",
    "                                                           180: \"multi\"})\n",
    "        # Se actualizan propiedades      \n",
    "\n",
    "        self.addCols({\"numericas\": ['TotalSF', 'Total_sqr_footage', 'Total_Bathrooms', 'Total_porch_sf'],\n",
    "                      \"nominales\": ['haspool', 'has2ndfloor', 'hasgarage', 'hasbsmt', 'hasfireplace', 'hasporch', \"hasRemodeled\", \"MSSubClassMap\"]})\n",
    "              \n",
    "        self.columns = self.df.columns\n",
    "        \n",
    "        \n",
    "    def corrDel(self, cols = None, Threshold = 0.90):\n",
    "        \"\"\"\n",
    "            Elimina variables que están correlacionadas según un threshold pasado por parámetro. \n",
    "\n",
    "            :param cols=None: lista de strings con nombre de las variables numéricas.\n",
    "            :param Threshold=0.9: umbral por encima del cual variables correlacionadas serán eliminadas.\n",
    "            \n",
    "            Valor de retorno: lista de strings con los nombres de las variables a eliminar \n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from itertools import chain\n",
    "        \n",
    "        if cols is not None:\n",
    "            \n",
    "            cor = self.df[cols].corr()\n",
    "            cor.loc[:,:] =  np.tril(cor, k=-1)\n",
    "            cor = cor.stack()\n",
    "            correlated = cor[cor > Threshold].reset_index().loc[:,['level_0','level_1']].query('level_0 not in level_1')\n",
    "            correlated_array =  correlated.groupby('level_0').agg(lambda x: set(chain(x.level_0,x.level_1))).values\n",
    "        \n",
    "            correlated_features = []\n",
    "\n",
    "            for sets in correlated_array:\n",
    "                element_list = list(sets[0])\n",
    "                for idx, elem in enumerate(element_list):\n",
    "                    if idx is not 0:\n",
    "                        correlated_features.append(elem)\n",
    "        \n",
    "            self.remCols(correlated_features)\n",
    "            \n",
    "            return correlated_features\n",
    "        \n",
    "    \n",
    "    def featureRFE(self, method='RF', cv=20, rango=10):\n",
    "        \"\"\"   \n",
    "            Aplicación del método de seleccion de variables para los siguientes estimadores:\n",
    "            -LR: regresión Lineal\n",
    "            -RF: random Forest \n",
    "\n",
    "            :param method='RF': aplicación del estimador\n",
    "            :param cv=20: número de particiones para crossvalidation\n",
    "            :rango: número de niveles para requeridos del ranking de variables según importancia\n",
    "            \n",
    "            Valor de retorno:\n",
    "            -lista de booleanos con variables de nivel 1, True, en el ranking de importancia\n",
    "            -lista de enteros con el valor del nivel según importancia\n",
    "            -diccionario con nombre de variables hasta nivel del ranking determinado en rango\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from sklearn.feature_selection import RFECV\n",
    "    \n",
    "        y = self.df[self.target].copy()\n",
    "        X = self.df.drop(self.target, axis=1).copy()\n",
    "    \n",
    "        if method == 'LR':\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "            rfe = RFECV(LinearRegression(), cv=cv).fit(X, y)\n",
    "        \n",
    "        elif method == \"RF\":\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "        \n",
    "            rfe = RFECV(RandomForestRegressor(), cv=cv).fit(X, y)\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "        imp = {i: list(X.columns[[True if j==i  else False for j in rfe.ranking_]]) for i in range(1,10)}\n",
    "        \n",
    "        return rfe.support_, rfe.ranking_, imp\n",
    "    \n",
    "    \n",
    "    def featureEmb(self, method='Lasso', cv=20, Threshold=0.0, table=False):\n",
    "        \"\"\"   \n",
    "            Aplicación del método de seleccion de variables para los siguientes estimadores:\n",
    "            -Lasso: regresión Lasso\n",
    "            -Ridge: regresión Ridge\n",
    "\n",
    "            :param method='Lasso': aplicación del estimador\n",
    "            :param cv=20: número de particiones para crossvalidation\n",
    "            :param Threshold=0.0: umbral por encima del cual las variables son consideradas importantes \n",
    "            :param table=False: booleano que indica si se quiere o no devolver algo en la función\n",
    "            \n",
    "            Valor de retorno: en el caso de table=True se devuelve un pandas Dataframe con nombre de variables.\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        y = self.df[self.target].copy()\n",
    "        X = self.df.drop(self.target, axis=1).copy()\n",
    "        \n",
    "        if method == 'Lasso':\n",
    "            from sklearn.linear_model import LassoCV\n",
    "            coef = pd.Series(LassoCV(cv=cv).fit(X, y).coef_, index = X.columns)\n",
    "        \n",
    "        elif method == 'Ridge':\n",
    "            from sklearn.linear_model import RidgeCV\n",
    "            coef = pd.Series(RidgeCV(cv=cv).fit(X, y).coef_, index = X.columns)\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        imp_coef = coef[abs(coef) > Threshold].sort_values(ascending=False)  \n",
    "        \n",
    "        plt.rc('xtick', labelsize=25)   \n",
    "        plt.rc('ytick', labelsize=25)\n",
    "        plt.rcParams.update({'figure.figsize': (40, 20)})\n",
    "        \n",
    "        imp_coef.plot(kind = \"bar\")\n",
    "        plt.title(\"IMPORTANCIA DE VARIABLES SEGÚN MODELO {}\\n(Threshold: {})\".format(method, Threshold), {'size':'30'})\n",
    "        \n",
    "        if table == True:\n",
    "            return pd.DataFrame(imp_coef[abs(imp_coef) > 0], columns=['coef']).style.background_gradient()\n",
    "        \n",
    "        \n",
    "    def outliersNaN(self, dic=None):\n",
    "        \"\"\"   \n",
    "            Transforma a NaN los valores de las variables pasadas por parámetro dic\n",
    "\n",
    "            :param dic=None: diccionario cuya 'key' es el nombre de la variable (tipo string) y cuyos 'value'\n",
    "            es una lista con los índices de las observaciones a transformar\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        \n",
    "        if dic is not None:\n",
    "            for key, value in dic.items():\n",
    "                self.df[key].loc[value] = np.nan\n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
